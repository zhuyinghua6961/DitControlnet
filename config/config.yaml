# ControlNet-DiT Training Configuration

# Model Configuration
model:
  img_size: 512
  patch_size: 16
  in_channels: 3
  out_channels: 3
  dim: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4.0

# Training Configuration
training:
  batch_size: 1  # RTX 3090 Ti 24GB 显存优化 - 调低以确保稳妥运行
  num_epochs: 100
  learning_rate: 0.00001  # 微调任务推荐更小的 LR，避免梯度爆炸
  weight_decay: 0.01
  gradient_clip_norm: 1.0
  save_interval: 10
  eval_interval: 10
  warmup_steps: 1000
  use_bucketing: false  # 是否使用长宽比分桶
  max_train_steps: null  # 最大训练步数，null表示使用num_epochs
  checkpointing_steps: 500  # 保存检查点间隔
  checkpoints_total_limit: null  # 最大检查点数量
  resume_from_checkpoint: null  # 恢复训练的检查点路径

# Diffusion Configuration
diffusion:
  num_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  schedule_type: "linear"

# Data Configuration
data:
  data_dir: "./dataset/dataset_fill50k"
  jsonl_dir: "./data"
  train_jsonl: "train.jsonl"
  eval_jsonl: "eval.jsonl"
  num_workers: 8  # 增加工作线程数
  pin_memory: true
  resolution: 512

# Logging and Saving
logging:
  log_dir: "./logs"
  checkpoint_dir: "./checkpoints"
  sample_dir: "./samples"
  use_wandb: true
  wandb_project: "controlnet-dit-fill50k"
  report_to: "tensorboard"  # tensorboard, wandb, all

# Hardware Configuration
hardware:
  device: "auto"  # auto, cuda, cpu
  mixed_precision: "bf16"  # no, fp16, bf16
  compile_model: false  # 是否编译模型
  gradient_checkpointing: true  # 启用梯度检查点节省显存
  use_8bit_adam: true  # 使用8-bit AdamW优化器
  allow_tf32: true  # 允许TF32加速
  dataloader_num_workers: 4  # 提升数据读取速度，避免 GPU 等待

# Loss Configuration
loss:
  type: "mse"  # mse, l1, huber
  reduction: "mean"
  snr_gamma: null  # SNR权重gamma，null表示不使用

# ControlNet Configuration
controlnet:
  zero_init: true  # 是否零初始化 ControlNet 层
  conditioning_scale: 1.0  # 条件控制强度

# Baseline Training Configuration (PixArt-alpha-XL-2)
baseline:
  pretrained_model_name_or_path: "PixArt-alpha/PixArt-XL-2-512x512"
  controlnet_model_name_or_path: null
  use_controlnet: false  # Switch for baseline vs ControlNet training
  output_dir: "./output/baseline"
  cache_dir: "/mnt/fast18/models_cache"
  seed: null
  gradient_accumulation_steps: 8  # 配合 BS=1，实现等效 BS=8 的收敛稳定性
  lr_scheduler: "constant"
  lr_warmup_steps: 1000  # 与 training 块保持一致
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay: 1e-2
  adam_epsilon: 1e-08
  max_grad_norm: 1.0
  use_ema: false
  non_ema_revision: null
  push_to_hub: false
  hub_token: null
  hub_model_id: null
  logging_dir: "logs"
  validation_prompt: null
  validation_image: null
  validation_steps: 500
  num_validation_images: 4
  max_train_samples: null
  enable_xformers_memory_efficient_attention: true

# Evaluation Configuration
evaluation:
  generated_images_dir: "./output/generated"
  condition_images_dir: "./data/conditions"
  real_images_dir: null
  prompts_file: null
  output_file: "evaluation_results.json"
  max_images: 100
  model_checkpoint: null